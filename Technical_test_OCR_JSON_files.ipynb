{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388f9387",
   "metadata": {},
   "source": [
    "# Extranting data from OCR JSON\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cf769",
   "metadata": {},
   "source": [
    "In the following notebook, I is show how to extract specific information of two specific OCR .json files. \n",
    "The information is presented as JSON format with the following structure:\n",
    "\n",
    "{'Date' : value,\n",
    " 'Store address' : value,\n",
    " 'Invoice number' : value,\n",
    " 'Subtotal' : value,\n",
    " 'Total' : value,\n",
    " 'Line items': values}\n",
    "\n",
    "Because two differents files are provided, I create severals functions for each one and funtions that can be executed for both files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38546e7c",
   "metadata": {},
   "source": [
    "## Import the necessary python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03d2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a11cd",
   "metadata": {},
   "source": [
    "## Load the .json file\n",
    "\n",
    " The path './OCR_ticket1.json' is the path for the provided samples. Change it to the path of your .json path.\n",
    " \n",
    " <p>ticket1 refers to JUMBO CALLE 80</p>\n",
    " <p>ticket2 refers to JUMBO VALLE DE LILI</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d12ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON files and load the JSON data \n",
    "\n",
    "with open('./OCR_ticket1.json', 'r') as file:\n",
    "    \n",
    "    ticket1 = json.load(file) \n",
    "\n",
    "with open('./OCR_ticket2.json', 'r') as file:\n",
    "    \n",
    "    ticket2 = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a674670",
   "metadata": {},
   "source": [
    "<p> Note: After looking the .json for both images, I concluded that the hole and relevant information was in one place: </p>\n",
    "<p> file_json['pages'][0]['textAnnotations'][0]['description'] </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7921fd7",
   "metadata": {},
   "source": [
    "## Function to extract the Shop adress\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6fbff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function read the shop adress. The .json files provided are the result of OCR process of two sell tickets \n",
    "of wo differents shops: JUMBO CALLE 80 and JUMBO VALLE DE LILI. \n",
    "So, this function only read the next forward string of the shop name.  \n",
    "\n",
    "'''\n",
    "\n",
    "def adress(b):\n",
    "    \n",
    "    c = []\n",
    "    \n",
    "    lent = np.arange(len(b))\n",
    "    \n",
    "    for i in lent:\n",
    "        if b[i] == 'JUMBO VALLE DE LILI':\n",
    "            c.append(b[i+1])\n",
    "        elif b[i] == 'JUMBO CALLE 80':\n",
    "            c.append(b[i+1])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efeff8",
   "metadata": {},
   "source": [
    "## Function to extrac the items of one .json\n",
    "\n",
    "This function only works for .json associated with CALLE 80 shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3cc7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    " Due to the structure of the file, it was necessary to identify the place \n",
    " where the required information of the sold items appeared. This function \n",
    " is responsible for finding the places where the required information is \n",
    " found and cleans the data for better manipulation.\n",
    " \n",
    "'''\n",
    "\n",
    "def items_calle80(text_split): \n",
    "    \n",
    "    tex = np.arange(len(text_split)) \n",
    "    \n",
    "    # Set the integers to use \n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    # Set the lists to use\n",
    "    \n",
    "    sku = []\n",
    "    desc = []\n",
    "    val = []\n",
    "    tax_ty = []\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    items = []\n",
    "    \n",
    "    # Determines where the block of interest begins and ends\n",
    "    \n",
    "    for i in tex:\n",
    "        if text_split[i] == '$': \n",
    "            start = i\n",
    "        if text_split[i] == 'SUBTOTAL.': \n",
    "            end = i\n",
    "    \n",
    "    # Extract the necesary data\n",
    "    \n",
    "    for i in np.arange(start+1,end,1):\n",
    "        data_1.append(text_split[i])      \n",
    "    \n",
    "    # This is necessary to remove unnecessary data\n",
    "    \n",
    "    data_1.remove('SUBTOTAL')\n",
    "    \n",
    "    # Split the data into rows\n",
    "    \n",
    "    for i in data_1:\n",
    "        data_2.append(i.split(' ',1))\n",
    "    \n",
    "    # Clean the data and create the atributes of the sell items in lits\n",
    "    \n",
    "    for i in data_2:\n",
    "        if (len(i) == 2):\n",
    "            if (len(i[0]) <= 8 and i[0].isnumeric() == True):\n",
    "                val.append(i[0])\n",
    "                tax_ty.append(i[1])\n",
    "            else: \n",
    "                sku.append(i[0])\n",
    "                desc.append(i[1])\n",
    "        \n",
    "        if (len(i) == 1):\n",
    "            if i[0].isnumeric() == True:\n",
    "                val.append(i[0])                \n",
    "            else:\n",
    "                tax_ty.append(i[0])\n",
    "        \n",
    "    # This is necesary becuase the tax code of the sell item is not always present \n",
    "    \n",
    "    for i in val:\n",
    "        if len(val) > len(tax_ty):\n",
    "            tax_ty.append('0')\n",
    "\n",
    "    create = np.arange(len(desc))\n",
    "    \n",
    "    # Return the list of items with the necessary atributes\n",
    "    \n",
    "    for i in create:\n",
    "        a = [sku[i],desc[i],val[i],tax_ty[i]]\n",
    "        items.append(a)\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0036470",
   "metadata": {},
   "source": [
    "## Function to extrac the items of one .json\n",
    "\n",
    "This function only works for .json associated with VALLE DE LILI shop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85da81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    " Due to the structure of the file, it was necessary to identify the place \n",
    " where the required information of the sold items appeared. This function \n",
    " is responsible for finding the places where the required information is \n",
    " found and cleans the data for better manipulation.\n",
    " \n",
    " In this case the data is much more disorganized and requires more cleanup.\n",
    " \n",
    "'''\n",
    "\n",
    "def items_valle_lili(text_split):\n",
    "    \n",
    "    \n",
    "    \n",
    "    tex = np.arange(len(text_split))\n",
    "    \n",
    "    # Set the integers to use \n",
    "    \n",
    "    start1 = 0\n",
    "    end1 = 0\n",
    "    start2 = 0\n",
    "    end2 = 0\n",
    "    \n",
    "    # Set the lists to use\n",
    "    \n",
    "    data_3 = []\n",
    "    items_str = []\n",
    "    data_4 = []\n",
    "    tazx = []\n",
    "    sku = []\n",
    "    desc = []\n",
    "    val = []\n",
    "    tax_ty = []\n",
    "    tems = []\n",
    "    \n",
    "    \n",
    "    # Determines where the block of interest begins and ends\n",
    "    \n",
    "    for i in tex:\n",
    "        if text_split[i] == 'VENDEDOR ELECTRO':\n",
    "            start1 = i\n",
    "        if text_split[i][0] == 'D':\n",
    "            end1 = i\n",
    "            break\n",
    "    \n",
    "    # Extract the necesary data\n",
    "    \n",
    "    for i in np.arange(start1+1,end1,1):\n",
    "        data_3.append(text_split[i])\n",
    "        \n",
    "    \n",
    "    # Clean and extract the necesary SKU and descriptions of the sell items\n",
    "    \n",
    "    for i in data_3:\n",
    "        if i != 'SUBTOTAL':\n",
    "            items_str.append(i.split(' ',1))\n",
    "    \n",
    "\n",
    "    # Choose the block of data that contain the price and tax code of the sell items\n",
    "    \n",
    "    for i in tex:\n",
    "        if (':' in text_split[i]):\n",
    "            start2 = i\n",
    "        if ('RESOL.' in text_split[i]):\n",
    "            end2 = i\n",
    "            break\n",
    "    \n",
    "    # Clean and extract the necesary data\n",
    "    \n",
    "    for i in tex:\n",
    "        if (end2 > i > start2 and ('-' not in text_split[i])):\n",
    "            data_4.append(text_split[i])\n",
    "            if ('-' in text_split[i+1]):\n",
    "                break\n",
    "    \n",
    "    # This is necessary to remove unnecessary data\n",
    "    \n",
    "    data_4.pop()\n",
    "    \n",
    "    # This is necessary to remove unnecessary data\n",
    "    \n",
    "    for i in np.arange(len(data_4)):\n",
    "        if (data_4[i+1] != data_4[i]):\n",
    "            data_4.remove(data_4[i+1])\n",
    "            break\n",
    "            \n",
    "    # This is necessary to remove unnecessary data\n",
    "    \n",
    "    for i in np.arange(len(data_4)):\n",
    "        if (data_4[i].isalpha() == True):\n",
    "            data_4.remove(data_4[i])\n",
    "            break\n",
    "    \n",
    "    # Store the necessary data\n",
    "    \n",
    "    for i in data_4:\n",
    "        tazx.append(i.split(' ',1))\n",
    "    \n",
    "    # Store the SKU and descriptions data\n",
    "    \n",
    "    for i in np.arange(len(items_str)):\n",
    "        sku.append(items_str[i][0])\n",
    "        desc.append(items_str[i][1])\n",
    "        \n",
    "    # Store the price and tax code data\n",
    "    \n",
    "    for i in tazx:\n",
    "        if (len(i) == 2):\n",
    "            if (len(i[0]) <= 8 and i[0].isnumeric() == True):\n",
    "                val.append(i[0])\n",
    "                tax_ty.append(i[1])\n",
    "            else: \n",
    "                sku.append(desc[i])\n",
    "        \n",
    "        if (len(i) == 1):\n",
    "            if i[0].isnumeric() == True:\n",
    "                val.append(i[0])\n",
    "                tax_ty.append('0')\n",
    "            else:\n",
    "                tax_ty.append(i[0])\n",
    "    \n",
    "    create = np.arange(len(desc))\n",
    "    \n",
    "    # Return the list of items with the necessary atributes\n",
    "\n",
    "    for i in create:\n",
    "        a = [sku[i],desc[i],val[i],tax_ty[i]]\n",
    "        tems.append(a)\n",
    "        \n",
    "    return tems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefdccc",
   "metadata": {},
   "source": [
    "## Function to extract the total & subtotal values of .json file\n",
    "\n",
    "This function only works for .json associated with CALLE 80 shop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f864c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This function extracts the total and subtotal values from the sales ticket\n",
    "of CALLE 80 shop\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def tot_and_sub_tot(split):\n",
    "    \n",
    "    total = np.arange(len(split))\n",
    "    tot = 0.0\n",
    "    sub_tot = 0.0\n",
    "\n",
    "    # Determines the position of the values\n",
    "    \n",
    "    for i in total:\n",
    "        if split[i] == 'TOTAL':\n",
    "            tot = float(split[i+1])\n",
    "            sub_tot = float(split[i+1])+float(split[i+2])\n",
    "            \n",
    "    return [tot,sub_tot]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd8b16",
   "metadata": {},
   "source": [
    "## Function to extract the total & subtotal values of .json file\n",
    "\n",
    "This function only works for .json associated with VALLE DE LILI shop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17d696dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This function extracts the total and subtotal values from the sales ticket\n",
    "of VALLE de LILI shop\n",
    "\n",
    "'''\n",
    "\n",
    "def tot_and_sub_tot_1(split):\n",
    "    \n",
    "    total = np.arange(len(split))\n",
    "    tot = 0.0\n",
    "    sub_tot = 0.0\n",
    "    \n",
    "    # Determines the position of the values\n",
    "    \n",
    "    for i in total:\n",
    "        if split[i] == 'TOTAL':\n",
    "            tot = float(split[i-2])-float(split[i-1])\n",
    "            sub_tot = float(split[i-2])\n",
    "    \n",
    "    return [tot,sub_tot]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d000ce4",
   "metadata": {},
   "source": [
    "## Function to extrac the date of OCR .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed62ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This function determines the date you made the purchase. Works for both stores.\n",
    "\n",
    "'''\n",
    "\n",
    "def date(text_split):\n",
    "    date = []\n",
    "    lent = np.arange(len(text_split))\n",
    "    \n",
    "    # Determines the position where the data is located\n",
    "    \n",
    "    for i in lent:\n",
    "        if ('/' in text_split[i] and (len(text_split[i]) == 10 and text_split[i][0].isalpha() != True )):\n",
    "            date.append(text_split[i])\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774cb28",
   "metadata": {},
   "source": [
    "## Function to extract the invoice number of the OCR .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf00b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This function determines the invoice number the purchase ticket. Works for both stores.\n",
    "\n",
    "'''\n",
    "\n",
    "def get_ticket(json):\n",
    "    \n",
    "    leng = np.arange(len(json['pages'][0]['textAnnotations']))\n",
    "\n",
    "    ticket = []\n",
    "\n",
    "    for i in leng:\n",
    "        if json['pages'][0]['textAnnotations'][i]['description'] == 'TIQUETE':\n",
    "            ticket.append(json['pages'][0]['textAnnotations'][i]['description']+\\\n",
    "                          ' '+json['pages'][0]['textAnnotations'][i+1]['description']\\\n",
    "                          +' '+json['pages'][0]['textAnnotations'][i+2]['description'])\n",
    "    \n",
    "    return ticket\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4678a",
   "metadata": {},
   "source": [
    "## Function to extract the requested information for JUMBO CALLE 80 shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5cf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_calle80(ticket_json):\n",
    "    \n",
    "    # In this line we indentify the hole extract text of the image and create a list for search the info\n",
    "    \n",
    "    text = ticket_json['pages'][0]['textAnnotations'][0]['description']\n",
    "    text_split = text.split('\\n')\n",
    "    \n",
    "    \n",
    "    tot,sub = tot_and_sub_tot(text_split)\n",
    "       \n",
    "    shop_adress = adress(text_split)\n",
    "        \n",
    "    date_ticktet = date(text_split)\n",
    "    \n",
    "    ticket_number = get_ticket(ticket_json)\n",
    "    \n",
    "    items_ticket = items_calle80(text_split)\n",
    "    \n",
    "    # Here the information is organized\n",
    "    \n",
    "    information =  {\n",
    "        'Date': date_ticktet[0],\n",
    "        'Store adress': shop_adress[0], \n",
    "        'Invocice number': ticket_number[0], \n",
    "        'Subtotal': sub, 'Total': tot,\n",
    "        'Items': items_ticket\n",
    "    }\n",
    "    \n",
    "    # The information is presented in JSON format \n",
    "    \n",
    "    information_json = json.dumps(information)\n",
    "    \n",
    "    return (information_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04e819",
   "metadata": {},
   "source": [
    "## Function to extract the requested information for JUMBO VALLE de LILI shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a9657aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_vallelili(ticket_json):\n",
    "    \n",
    "    # In this line we indentify the hole extract text of the image and create a list for search the info\n",
    "    text = ticket_json['pages'][0]['textAnnotations'][0]['description']\n",
    "    text_split = text.split('\\n')\n",
    "    \n",
    "    \n",
    "    tot,sub = tot_and_sub_tot_1(text_split)\n",
    "    \n",
    "    shop_adress = adress(text_split)\n",
    "    \n",
    "    date_ticktet = date(text_split)\n",
    "\n",
    "    ticket_number = get_ticket(ticket_json)\n",
    "    \n",
    "    items_ticket = items_valle_lili(text_split)\n",
    "       \n",
    "    # Here the information is organized\n",
    "    \n",
    "    information =  {\n",
    "        'Date': date_ticktet[0],\n",
    "        'Store adress': shop_adress[0], \n",
    "        'Invocice number': ticket_number[0], \n",
    "        'Subtotal': sub, 'Total': tot, \n",
    "        'Items':items_ticket\n",
    "    }\n",
    "    \n",
    "    # The information is presented in JSON format \n",
    "    \n",
    "    information_json = json.dumps(information)\n",
    "    \n",
    "    \n",
    "    return(information_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a547c369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Date\": \"10/12/2021\", \"Store adress\": \"AVENIDA CALLE 80 No 69Q- 50 TEL:6387000\", \"Invocice number\": \"TIQUETE J122 249302\", \"Subtotal\": 86160.0, \"Total\": 77733.0, \"Items\": [[\"8410270241140\", \"Aceite oliva SU\", \"27990\", \"N\"], [\"7707322030489\", \"Quinua QUINOACL\", \"7990\", \"A\"], [\"7707322030489\", \"Quinua QUINOACL\", \"7990\", \"A\"], [\"8004690751060\", \"Cous cous LA MO\", \"8990\", \"N\"], [\"7702247011056\", \"YOGURT LIQUIDO\", \"2650\", \"A\"], [\"8410971033785\", \"Aceitunas EXCEL\", \"3490\", \"N\"], [\"7707298470074\", \"Tallarines BEST\", \"8790\", \"A\"], [\"7702085003497\", \"Quinua molida D\", \"8690\", \"A\"], [\"7705326077837\", \"Tortillinas BIM\", \"5990\", \"N\"], [\"7702253800002\", \"Maiz pira TOT-R\", \"3590\", \"0\"]]}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_info_calle80(ticket1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f755743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Date\": \"04/11/2021\", \"Store adress\": \"CARRERA 98 No 16-50\", \"Invocice number\": \"TIQUETE J212 341304\", \"Subtotal\": 174196.0, \"Total\": 151731.0, \"Items\": [[\"7702406000150\", \"Azucar refinado\", \"8590\", \"A\"], [\"7702406000150\", \"Azucar refinado\", \"8590\", \"A\"], [\"7702406000150\", \"Azucar refinado\", \"8590\", \"A\"], [\"7702406000150\", \"Azucar refinado\", \"8590\", \"A\"], [\"7702020212052\", \"DONAREPA PERLAD\", \"3690\", \"A\"], [\"7702020212052\", \"DONAREPA PERLAD\", \"3690\", \"A\"], [\"7705491102020\", \"PANELA EXTRA RE\", \"4390\", \"0\"], [\"7705491102020\", \"PANELA EXTRA RE\", \"4390\", \"0\"], [\"7702026020507\", \"Servilleta FAMI\", \"6590\", \"N\"], [\"7702010225123\", \"FABULOSO LAVAND\", \"6590\", \"F\"], [\"7701018005089\", \"ACEITE OLEOCALI\", \"48790\", \"N\"], [\"7500435126823\", \"Shampoo H&S lim\", \"27990\", \"N\"], [\"7622201772840\", \"Gelatina ROYAL\", \"3890\", \"N\"], [\"7509546672557\", \"Desodorante SPE\", \"33990\", \"N\"], [\"7702026193003\", \"Papel hig. FAMIL\", \"28990\", \"N\"]]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_info_vallelili(ticket2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
